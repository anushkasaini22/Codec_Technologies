# -*- coding: utf-8 -*-
"""Heart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/anushkasaini22/Codec_Technologies/blob/main/Heart.ipynb

**DATA VISUALIZATION**
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
# %matplotlib inline

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 150)
sns.set_style('darkgrid')
matplotlib.rcParams['font.size'] = 14
matplotlib.rcParams['figure.figsize'] = (10, 6)
matplotlib.rcParams['figure.facecolor'] = '#00000000'

heart_df = pd.read_csv('/content/heart (1).csv')
heart_df.head()

heart_df.info()

heart_df.describe()

heart_df.target.value_counts()

heart_df["target"].value_counts().plot(kind="bar")

heart_df["sex"].value_counts().plot(kind="bar")

pd.crosstab(heart_df.target, heart_df.sex).plot(
    kind="bar",
    figsize=(10, 6),
    color=["blue", "red"]
)
plt.title("Heart Disease Frequency by Sex")
plt.xlabel("0 = No Disease, 1 = Disease")
plt.ylabel("Counts")
plt.legend(["Female (0)", "Male (1)"])
plt.xticks([0, 1], ["No Disease", "Disease"])
plt.xticks(rotation=0)
plt.show()

# check the distribution of the age column with a histogram
heart_df.age.plot.hist()
plt.xlabel("Age")
plt.ylabel("Frequency")
plt.title("Distribution of Age")

pd.crosstab(heart_df.cp, heart_df.target).plot(kind="bar",
                                    figsize=(10,6),
                                    color=["salmon","lightblue"])
plt.title("heart disease frequency per chest pain type")
plt.xlabel("Chest Pain Type")
plt.ylabel("Counts")
plt.legend(["No Disease", "Disease"])
plt.xticks(rotation=0);

heart_df.corr()

corr_matrix = heart_df.corr()
fig, ax =plt.subplots(figsize=(15,10))
ax = sns.heatmap(corr_matrix,
                 annot =True,
                 linewidths=0.5,
                 fmt=".2f",
                 cmap="YlGnBu")
bottom, top = ax.get_ylim()
ax.set_ylim(bottom+0.5,top-0.5)

plt.figure(figsize=(8, 12))
corr = heart_df.corr()
sorted_corr = corr[['target']].drop(index='target') \
                              .sort_values(by='target', ascending=False) \
                              .head(5)
sns.heatmap(sorted_corr, cmap='Greens', annot=True)
plt.title('Top 5 Features Correlated with Target')
plt.show()

heart_df.hist(xrot=-45,figsize=(45,25))
plt.show()

"""**PREPARING FOR DATA MODEL TRAINING**"""

target_col = heart_df["target"]
input_cols = heart_df.drop("target", axis=1)

target_col

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
input_cols = scaler.fit_transform(input_cols)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(input_cols, target_col, test_size=0.2, random_state=42)

"""**MODEL TRAINING**"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

model1 = LogisticRegression()
model1.fit(X_train,y_train)
Y_pred = model1.predict(X_test)
print("Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test,Y_pred))

model2 = KNeighborsClassifier(n_neighbors=3)
model2.fit(X_train,y_train)
Y_pred = model2.predict(X_test)
print("Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test,Y_pred))

model3 = SVC()
model3.fit(X_train,y_train)
Y_pred = model3.predict(X_test)
print("Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test,Y_pred))

model4 = DecisionTreeClassifier(max_features=2, max_depth=10, criterion='gini', random_state=42)
model4.fit(X_train,y_train)
Y_pred = model4.predict(X_test)
print("Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test,Y_pred))

model5 = GaussianNB()
model5.fit(X_train, y_train)
Y_pred = model5.predict(X_test)
print("Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test, Y_pred))

model6 = RandomForestClassifier(n_estimators=200, max_depth=10, max_features=5, bootstrap=True, random_state=42, n_jobs=-1)
model6.fit(X_train, y_train)
Y_pred = model6.predict(X_test)
print("Random Forest Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test, Y_pred))

model7 = XGBClassifier(n_estimators=200, learning_rate=0.01, max_depth=6, random_state=42)
model7.fit(X_train, y_train)
Y_pred = model7.predict(X_test)
print("Accuracy: {:.2f}%".format(accuracy_score(y_test, Y_pred) * 100))
print(classification_report(y_test, Y_pred))

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
langs = ['Log-Reg', 'KNN', 'SVC', 'Des-Tree', 'Gaus-NB', 'RandomForest', 'Xgboost']
students = [81.46, 93.17, 86.83, 91.71, 80.00, 98.54, 96.10]
ax.bar(langs,students)
plt.show()

from sklearn.model_selection import StratifiedKFold, cross_val_score

# 4️⃣ Stratified K-Fold CV on training set
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model4, X_train, y_train, cv=cv, scoring='accuracy')

print("CV Scores(For Decision Tree):", cv_scores)
print("CV Mean Accuracy: {:.2f}%".format(np.mean(cv_scores) * 100))
print("CV Std Deviation: {:.2f}".format(np.std(cv_scores)))

# 5️⃣ Train final model on full training set
model4.fit(X_train, y_train)

# 6️⃣ Test set evaluation
y_pred = model4.predict(X_test)
print("\nTest Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred) * 100))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import StackingClassifier

# Base models
base_models = [
    ('logreg', model1),
    ('xgb', model7),
    ('dt', model4)
]

# Meta model
meta_model = LogisticRegression()

# Stacking
stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=5
)

# Fit
stack_model.fit(X_train, y_train)

# Predictions
y_pred = stack_model.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""**Saving model and testing on a custom input**"""

import joblib
joblib.dump(stack_model, "stacking_model.pkl")

model = joblib.load("stacking_model.pkl")
data_dict = {
    "age": 63,
    "sex": 1,
    "cp": 3,
    "trestbps": 145,
    "chol": 233,
    "fbs": 1,
    "restecg": 0,
    "thalach": 150,
    "exang": 0,
    "oldpeak": 2.3,
    "slope": 0,
    "ca": 0,
    "thal": 1
}

single_df = pd.DataFrame([data_dict])

scaled_input = scaler.transform(single_df)

pred_class = model.predict(scaled_input)

pred_proba = model.predict_proba(scaled_input)[0]

if(pred_class[0] == 0):
  print("Person does not have heart disease")
  print("Prediction Probability: {:.2f}%".format(max(pred_proba)*100))
else:
  print("Person has heart disease")
  print("Prediction Probability: {:.2f}%".format(max(pred_proba)*100))

data_dict={
    "age":float(input("Enter age: ")),
    "sex":float(input("Enter sex:(1=male,0=female): ")),
    "cp":float(input("Enter chestpain type(0-3): ")),
    "trestbps":float(input("Enter resting blood pressure: ")),
    "chol":float(input("Enter cholesterol level: ")),
    "fbs":float(input("Enter fasting blood sugar>120mg/dl(1=yes,0=no): ")),
    "restecg":float(input("Enter resting ECG results(0-2): ")),
    "thalach":float(input("Enter max heart rate achieved: ")),
    "exang":float(input("Enter exercise induced angina(1=yes,0=no): ")),
    "oldpeak":float(input("Enter ST Depression: ")),
    "slope":float(input("Enter slope of peak exercise ST segment(0-2): ")),
    "ca":float(input("Enter number of major vessels colored by flourosopy(0-3): ")),
    "thal":float(input("Enter thalassemia(1=normal;2=fixed defect;3=reversible defect): "))

}
single_df=pd.DataFrame([data_dict])
scaled_input=scaler.transform(single_df)
prediction=model.predict(scaled_input)




#Output result
if prediction==1:
    print("****Person has heart disease****")
else:
    print("*****Person does not have heart disease****")