
# Codec_Technologies
This heart disease detection project uses machine learning to predict if a person has heart disease based on medical features like age, blood pressure, cholesterol, and ECG results. It collects user inputs, applies preprocessing (scaling), and runs a trained model to give a clear prediction output. 

# PROJECT NAME 
### Healthcare Predictive Analytics (Disease Detection): The Heart Diseases Risk Detection

# Image


<img width="2304" height="768" alt="Risk_of_heart_disease_banner1" src="https://github.com/user-attachments/assets/2049dbf0-c908-4a5b-89e6-ce1419b017e8" />


# Heart Disease Detection

This project predicts heart disease presence using machine learning based on user-input medical data. It takes key health features like age, blood pressure, cholesterol, ECG results, and more to provide a quick diagnosis.


## Requirements
- Python 3.x  
 

## Goal 
 Predict risk of Heart Diseases.
 
## Features
- Use Kaggle datasets.
-Normalize medical records for consistency.
-Apply classification models with feature importance analysis.
-Highlight ethical data handling and patient privacy.
- User-friendly input prompts
- Data preprocessing with scaling
- Accurate prediction with a trained model
- Output clearly states if the person has heart disease or not



## Dataset Link From Kaggle 
Link: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset/data

## Libraries and Packages used for the project

Pandas,Numpy,Seaborn,Matplotlib,Scikit-learn.

## Model Training Used for the Project

LogisticRegression,KNeighborsClassifier, DecisionTreeClassifier,SVN,GaussianNB, RandomForestClassifier,XGBClassifier.

## The Script Output
- Accuracy and classification metrics.
- Confusion matrix.
- Feature importance bar chart.
- Sample predictions indicating 0 for disease presence and 1 for disease absence

  ## Ethical Consideration
- All patient data should be anonymized to protect privacy.
- The dataset usage must comply with Kaggleâ€™s terms and any relevant healthcare data regulations such as HIPAA or GDPR.
- Model results should be interpreted cautiously and not replace professional medical advice.
- Monitoring data bias and model fairness is crucial to avoid harmful impacts.

## Notes
- Ensure the model and scaler objects are trained and saved properly before running  
- Input values must be within medically valid ranges  







